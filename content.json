{"meta":{"title":"logerJava","subtitle":"","description":"","author":"loger","url":"http://logerJava.github.io","root":"/"},"pages":[{"title":"categories","date":"2018-09-30T09:25:30.000Z","updated":"2022-11-04T08:29:46.112Z","comments":true,"path":"categories/index.html","permalink":"http://logerjava.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-11-09T06:13:45.000Z","updated":"2022-11-09T06:23:30.896Z","comments":false,"path":"about/index.html","permalink":"http://logerjava.github.io/about/index.html","excerpt":"","text":"互联网砖工"},{"title":"tags","date":"2018-09-30T10:23:38.000Z","updated":"2022-11-04T08:31:26.145Z","comments":true,"path":"tags/index.html","permalink":"http://logerjava.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"KeyTool 工具生成密钥对","slug":"KeyTool-工具生成密钥对","date":"2022-11-09T05:56:50.000Z","updated":"2022-11-09T06:06:56.971Z","comments":true,"path":"2022/11/09/KeyTool-工具生成密钥对/","link":"","permalink":"http://logerjava.github.io/2022/11/09/KeyTool-%E5%B7%A5%E5%85%B7%E7%94%9F%E6%88%90%E5%AF%86%E9%92%A5%E5%AF%B9/","excerpt":"","text":"生成 JKS1keytool -genkeypair -alias *** -keyalg RSA -keypass *** -keystore xxx.jks -storepass *** -keystore xxx.jks 查看 JKS 生成的证书详细信息1keytool -list -v -keystore xxx.jks 导出 cer 证书1keytool -alias *** -exportcert -keystore xxx.jks -file xxx.cer 导出公钥, 此处命令需要 OpenSSL , 并配置环境变量1keytool -list -rfc --keystore xxx.jks | openssl x509 -inform pem -pubkey 拷贝出公钥","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://logerjava.github.io/tags/Tools/"}]},{"title":"Linux 安装 JDK","slug":"Linux-安装-JDK","date":"2022-11-09T05:56:00.000Z","updated":"2022-11-09T05:56:22.285Z","comments":true,"path":"2022/11/09/Linux-安装-JDK/","link":"","permalink":"http://logerjava.github.io/2022/11/09/Linux-%E5%AE%89%E8%A3%85-JDK/","excerpt":"","text":"下载 tar.gz 包 12解压到指定位置tar -zxvf jdk.tar.gz -C /目录 12配置环境变量vim /etc/profile 12345export JAVA_HOME=/jdk/jdk1.8.0_311export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib:$CLASSPATHexport JAVA_PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JRE_HOME&#125;/binexport PATH=$PATH:$&#123;JAVA_PATH&#125; 12让配置文件立即生效, 不行就重启source /etc/profile javac, java -verison 测试是否成功 echo $PATH 查看环境变量是否正确","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://logerjava.github.io/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"http://logerjava.github.io/tags/Linux/"}]},{"title":"Linux 集群部署 Nacos","slug":"Linux-集群部署-Nacos","date":"2022-11-09T05:55:13.000Z","updated":"2022-11-09T05:55:45.354Z","comments":true,"path":"2022/11/09/Linux-集群部署-Nacos/","link":"","permalink":"http://logerjava.github.io/2022/11/09/Linux-%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2-Nacos/","excerpt":"","text":"在 nacos.io 下载 tar.gz 包, 导入 linux 解压 因为 nacos 集群部署, 各个节点配置信息需要一致, 所以采取 MySQL 持久化 找到 &#x2F;conf 下的 nacos-mysql.sql 文件, 在 MySQL 执行 修改 application.properties 文件, 添加如下配置 : 1234567spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://10.1.30.114:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user.0=rootdb.password.0=1qaz@WSX 在 &#x2F;conf 下 的 cluster.conf 文件, 添加节点 ip 和 port, 例如: 12310.1.30.111:884810.1.30.112:884810.1.30.113:8848 启动 nacos 1sh startup.sh 如果出现 oom 问题, 编辑 startup.sh, 调整 jvm 内存 : 1-server -Xms512m -Xmx512m -Xmn256m -XX:MetaspaceSize=64m -XX:MaxMetaspaceSize=128m 如果出现 12Nacos Server did not start because dumpservice bean construction failure :No DataSource set 原因可能是因为 MySQL 没有给当前 ip 开放 1grant all privileges on *.* to root@&quot;xxx.xxx.xxx.xxx&quot; identified by &quot;1qaz@WSX&quot;; 如果在浏览器无法访问, 可能原因是端口未在防火墙开放 1iptables -I INPUT -p tcp --dport 8848 -j ACCEPT","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://logerjava.github.io/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"http://logerjava.github.io/tags/Linux/"},{"name":"Nacos","slug":"Nacos","permalink":"http://logerjava.github.io/tags/Nacos/"}]},{"title":"Linux 安装 MySQL","slug":"Linux-安装-MySQL","date":"2022-11-09T05:54:14.000Z","updated":"2022-11-09T05:54:43.740Z","comments":true,"path":"2022/11/09/Linux-安装-MySQL/","link":"","permalink":"http://logerjava.github.io/2022/11/09/Linux-%E5%AE%89%E8%A3%85-MySQL/","excerpt":"","text":"安装 Mysql执行脚本12345678910安装 MySQLcurl https://webfile.newbanker.cn/mysql/install_centos7.sh -q | bash -s记录临时密码登录mysql修改mysql密码 mysql -u root -p输入数据安装后显示的密码set password for root@&#x27;localhost&#x27;=password(&#x27;1qaz@WSX&#x27;); 可能会遇到得问题SELinux linux服务器的安全策略问题1Can&#x27;t create test file /data/mysql/test-mysql.lower-test 安全策略问题, 可临时关闭 1setenforce 0 永久关闭需要修改配置文件，重启机器： 修改&#x2F;etc&#x2F;selinux&#x2F;config 文件 将SELINUX&#x3D;enforcing改为SELINUX&#x3D;disabled MySQL 不允许远程连接可能导致的原因 : 网络不通 服务未启动 1service mysqld start; 防火墙端口未开放 12345查看网络端口信息netstat -ntp查看防火墙状态,查看3306端口iptables -vnL 如果3306如下，是drop状态，或者根本无3306端口，说明3306端口设置问题 12添加需要监听的端口/sbin/iptables -I INPUT -p tcp --dport 3306 -j ACCEPT MySQL 没有允许远程登陆 12345678root 权限登录mysql -u root -p输入use mysql;查看是否只有 localhost 主机select user,host from user; 如果只有 localhost 主机, 那么把需要远程连接的添加到这里 1grant all privileges on *.* to root@&quot;xxx.xxx.xxx.xxx&quot; identified by &quot;1qaz@WSX&quot;; 1flush privileges;","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://logerjava.github.io/tags/Linux/"},{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"}]},{"title":"ShardingSphere-JDBC 读写分离","slug":"ShardingSphere-JDBC-读写分离","date":"2022-11-09T05:42:40.000Z","updated":"2022-11-09T06:02:38.213Z","comments":true,"path":"2022/11/09/ShardingSphere-JDBC-读写分离/","link":"","permalink":"http://logerjava.github.io/2022/11/09/ShardingSphere-JDBC-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/","excerpt":"","text":"为什么要读写分离 ?随着我们系统的业务量扩展, 原有的单机 MySQL 肯定会发生 I&#x2F;O 频率过高等问题, 导致损失性能, 采用主从复制, 读写分离可以提高数据库的可用性, 以及利用率 实现方式读写分离有很多种实现方式, 比如 AOP 的方式通过方法名判断是读操作还是写操作, 进而使用 master 或 slave , 但是本着不重复造轮子的原则, 以及现有框架成熟度很高我们采取 Apache 的 ShardingSphere-JDBC 框架, 该框架不仅可以实现读写分离, 还有很多其他便利功能, 这里仅对读写分离进行简单讲解 ShardingSphere-JDBC 官方文档 - https://shardingsphere.apache.org/document/current/cn/overview/ 示例项目项目配置pom 文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.12.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.76&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.22&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml这里采用一主一从 12345678910111213141516171819202122232425spring: shardingsphere: datasource: names: master,slave master: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://10.1.30.114:3306/test-db?useUnicode=true&amp;characterEncoding=utf8&amp;tinyInt1isBit=false&amp;useSSL=false&amp;serverTimezone=GMT username: root password: 1qaz@WSX slave: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://10.1.30.113:3306/test-db?useUnicode=true&amp;characterEncoding=utf8&amp;tinyInt1isBit=false&amp;useSSL=false&amp;serverTimezone=GMT username: root password: 1qaz@WSX props: sql.show: true masterslave: load-balance-algorithm-type: round_robin sharding: master-slave-rules: master: master-data-source-name: master slave-data-source-names: slave 启动启动看到如下提示则代表配置成功 读写接口测试我们编写两个简单的读写接口 使用 postman 请求访问, 可以看到 insert 走的是 master, select 走的是 slave","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://logerjava.github.io/tags/Java/"},{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"}]},{"title":"MySQL Explain","slug":"MySQL-Explain","date":"2022-11-09T05:37:44.000Z","updated":"2022-11-09T06:02:13.607Z","comments":true,"path":"2022/11/09/MySQL-Explain/","link":"","permalink":"http://logerjava.github.io/2022/11/09/MySQL-Explain/","excerpt":"","text":"关于 ExplainExplain 查询字段的含义 字段 含义 id 该语句的唯一标识 select_type 查询类型 table 表名 type 联接类型 possible_keys 可能的索引选择 key 实际选择的索引 key_len 索引的长度 ref 索引的哪一列被引用了 rows 估计要扫描的行 Extra 附加信息 id该语句的唯一标识, 如果 explain 的结果包括多个 id 的值, 则数字越大越先执行; 对于相同 id 的行, 则表示从上向下依次执行 select_type查询类型, 具体如下表 : 查询类型 作用 SIMPLE 简单查询(未使用 UNION 或子查询) PRIMARY 最外层查询 UNION 在 UNION 中的第二个和随后的 SELECT 被标记为 UNION DEPENDENT UNION UNION 中的第二个或后面的查询, 依赖了外面的查询 UNION RESULT UNION 的结果 SUBQUERY 子查询中的第一个 SELECT DEPENDENT SUBQUERY 子查询中的第一个 SELECT , 依赖了外面的查询 DERIVED 用来表示包含在 FROM 子句的子查询中的 SELECT , MySQL 会递归执行并将结果放到一个临时表中 (MySQL 内部将其称为 Derived table 派生表, 因为该表是从子查询中派生出来的) DEPENDENT DERIVED 派生表, 依赖了其他的表 MATERIALIZED 物化子查询 UNCACHEABLE SUBQUERY 子查询, 结果无法缓存, 必须针对外部查询的每一行重新评估 UNCACHEABLE UNION UNION 属于 UNCACHEABLE SUBQUERY 的第二个或后面的查询 table表示当前这一行正在访问哪张表, 如果 SQL 定义了别名, 则展示表的别名 type联接类型, 取值如下 (性能由好到坏排序) : system : 该表只有一行(相当于系统表), system 是 const 类型的特例 const : 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据; const 查询速度非常快, 因为仅仅读取一次即可 eq_ref : 当使用了索引的全部组成部分, 并且索引是 PRIMARY KEY 或 UNIQUE NOT NULL 才会使用该类型, 性能仅次于 system 和 const ref : 当满足索引的最左前缀规则, 或者索引不是主键也不是唯一索引时才会发生, 如果使用的索引只会匹配到少量的行, 性能也是不错的 tips : 最左前缀原则, 指索引按最左优先的方式匹配索引 fulltext : 全文索引 ref_or_null : 该类型类似 ref , 但是 MySQL 会额外搜索哪些行包含了 null, 常见于解析子查询 index_merge : 表示使用索引合并优化, 表示一个查询里面用到了多个索引 unique_subquery : 类似 eq_ref , 但是使用了 IN 查询, 且子查询是主键或者唯一索引 index_subquery : 和 unique_subquery 类似, 只是子查询使用的是唯一索引 range : 范围扫描, 表示检索了指定范围的行, 主要用于有限制的索引扫描 index : 全索引扫描, 和 ALL 类似, 只不过 index 是全盘扫描了索引的数据. 当查询仅使用索引中的一部分时, 可使用此类型, 有两种情况会触发 : 如果索引是查询的覆盖索引, 并且索引查询的数据就可以满足查询中所需的所有数据,则只扫描索引树. 此时, explain 的 Extra 列的结果是 Using index. index 通常比 ALL 快, 因为索引的大小通常小于表数据 按索引的顺序来查找数据行, 执行了全表扫描. 此时, explain 的 Extra 列的结果不会出现 Uses index ALL : 全表扫描, 性能最差 possible_keys展示当前查询可以使用那些索引, 这一列的数据是在优化过程的早期创建的, 因此有些索引可能对于后续优化过程是没用的 key表示 MySQL 实际选择的索引 key_len索引使用的字节数, 由于存储格式, 当字段允许为 NULL 时, key_len 比不允许为空时大 1 字节关于 key_len 的计算 : key_len 计算 ref表示将哪个字段或常量和 key 列所使用的字段进行比较 如果 ref 是一个函数, 则使用的值是函数的结果, 如果想查看是哪个函数, 可以在 EXPLAIN 语句后添加 SHOW WARNING 语句 rowsMySQL 估算会扫描的行数, 数值越小越好 Extra主要包括 Using filesort 、Using temporary 、Using index、Using where、Using join buffer、impossible where、select tables optimized away、distinct Using filesort : 说明 MySQL 会对数据使用一个外部的索引排序, 而不是按照表内的索引顺序进行读取; MySQL 中无法利用索引完成的排序操作称为 “文件排序” Using temporary : 使用了临时表保存中间结果, MySQL 在对查询结果排序时使用临时表; 常见于排序 order by 和分组 group by Using index : 表示相应 select 操作中使用了覆盖索引, 避免回表; 如果同时出现 Using where, 表明索引被用来执行索引键值的查找; 如果没有出现 Using where, 表明索引只是用来读取数据而非利用索引执行查找 Using where : 表明使用 where 过滤 Using join buffer : 表明使用了连接缓存 impossible where : where 的子句值总是 false select tables optimized away : 在没有 group by 子句的情况下, 基于索引优化 min&#x2F;max 操作或者对于 MyIsam 引擎, 优化 count(*) 操作, 不必等到执行阶段进行计算, 直接查询执行计划生成的阶段完成优化 distinct : 优化 distinct 操作, 在找到第一匹配的元组后即停止找同样值的动作 ……","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"}]},{"title":"MySQL 关于时间的一些思考","slug":"MySQL-时间的一些思考","date":"2022-11-09T05:36:42.000Z","updated":"2022-11-09T06:02:26.400Z","comments":true,"path":"2022/11/09/MySQL-时间的一些思考/","link":"","permalink":"http://logerjava.github.io/2022/11/09/MySQL-%E6%97%B6%E9%97%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/","excerpt":"","text":"关于 DateTime 和 Timestamp从时区方面考虑DateTime 没有时区信息, DateTime 在保存时保存的是当前会话所设置的时区对应的时间, 当时区更换会导致数据库读取时间出错Timestamp 存在时区信息, Timestamp 会跟随服务器的时区变化而变化, 自动换算成对应时间, 不同时区查询的时间是不同的 从占用空间, 时间范围方面考虑DateTime 耗费的空间更大, Timestamp 占用 4 个字节的存储空间, DateTime 占用 8 个字节的存储空间, 因此 Timestamp 表示的时间范围更小 DateTime : 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 Timestamp : 1970-01-01 00:00:01 ~ 2037-12-31 23:59:59 不要使用字符串存储时间使用字符串存储时间占用的空间更大, 效率较低(需要逐个字符对比), 无法使用相关函数进行计算和比较 不建议使用 int 和 bigint 表示时间此种存储方式拥有 Timestamp 类型具有的优点, 并且使用 int 和 bigint 进行日期排序和对比操作会更有效率, 跨系统也没有什么问题, 但是可读性很差, 无法看到具体时间 总结综上所述, 是关于 MySQL 中时间的一些思考, 可以看出关于 MySQL 的时间选择实际没有一种特定的最优解, 根据不同的业务场景应选择最适合的存储方法, 下面是各种类型的对比 : 日期类型 存储空间 日期格式 日期范围 是否存在时区问题 DateTime 8 字节 YYYY-MM-DD HH:MM:SS 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 是 Timestamp 4 字节 YYYY-MM-DD HH:MM:SS 1970-01-01 00:00:01 ~ 2037-12-31 23:59:59 否 时间戳 4 字节 全数字 1970-01-01 00:00:01 之后的时间 否","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"}]},{"title":"MySQL 高性能优化","slug":"MySQL-高性能优化","date":"2022-11-09T05:35:31.000Z","updated":"2022-11-09T06:02:19.564Z","comments":true,"path":"2022/11/09/MySQL-高性能优化/","link":"","permalink":"http://logerjava.github.io/2022/11/09/MySQL-%E9%AB%98%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","excerpt":"","text":"数据库命令规范 数据库对象名称使用小写字母, 下划线分割 数据库对象名称禁止使用 MySQL 关键字 数据库对象名称做到见名识意, 不要超过 32 字符 临时库表以 tmp_ 前缀, 日期为后缀; 备份表以 bak_ 为前缀, 日期为后缀 存储相同数据的列名和列类型必须一致 数据库基本设计规范1. 所有表均使用 Innodb 存储引擎在没有特殊需求的情况下(即 Innodb 无法满足的功能), 所有表必须使用 Innodb 存储引擎 2. 数据库和表的字符集统一使用 UTF8兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储emoji表情的需要，字符集需要采用utf8mb4字符集 3. 所有表和字段都需要添加注释4. 尽量控制单表数据量大小在 500 万以内单表数据量过大, 在修改表结构, 进行表备份, 恢复等操作时会出现问题, 可以通过分库分表手段控制表大小 5. 谨慎使用分区表分区表在物理上表现为多个文件，在逻辑上表现为一个表, 谨慎选择分区键，跨分区查询效率可能更低, 建议采用物理分表的方式管理大数据 6. 条件允许尽量冷热数据分离, 减小表宽度MySQL 限制单表最多存储 4096 列, 并且每一行数据的大小不能超过 65535 字节减少磁盘 IO, 表越宽, 将表加载到内存缓冲池时所占用的内存也就越大, 会消耗更多的 IO , 保证热数据的内存缓存命中率, 更有效的利用缓存, 避免读入无用的冷数据, 经常一起使用的列可以放到一个表中(避免过多的关联操作) 7. 禁止在表中建立预留字段预留字段的命名很难做到见名识义, 预留字段无法确认存储的数据类型，所以无法选择合适的类型, 对预留字段类型的修改，会对表进行锁定 8. 禁止在数据库中存储图片, 文件等大的二进制数据通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机IO操作，文件很大时，IO操作很耗时,通常存储于文件服务器，数据库只存储文件地址信息 9. 禁止在生产库做压力测试10. 禁止在开发, 测试环境直接连接生产环境数据库数据库字段设计规范1. 优先选择符合存储需要的最小的数据类型列的字段越大, 建立索引时所需要的空间也就越大, 这样一页中所能存储的索引节点的数量也就越少, 在遍历时需要的 IO 次数也就越多, 索引性能也就越差 example : 将字符串转换为数字类型存储(ip 地址转换为整型数据) MySQL 提供了两个方法来处理 ip 地址 inet_aton 把ip转为无符号整型(4-8位) inet_ntoa 把整型的ip转为地址 插入数据前，先用inet_aton把ip地址转为整型，可以节省空间, 显示数据时，使用inet_ntoa把整型的ip地址转为地址显示即可 对于非负型的数据（如自增 id、整型 ip）来说，要优先使用无符号整型来存储 因为, 无符号相对于有符号可以多出一倍的存储空间 SIGNED INT -21474836482147483647 UNSIGNED INT 04294967295 VARCHAR(N)中的N代表的是字符数，而不是字节数, 使用 UTF8 存储 255 个汉字, Varchar(255)&#x3D;765个字节, 过大的长度会消耗更多的内存 2. 避免使用 TEXT, BLOB 数据类型, 最常见的 TEXT 类型可以存储 64k 的数据建议将 BLOB 或 TEXT 列分离到单独的扩展表中 :MySQL 内存临时表不支持 TEXT, BLOB 这样的大数据类型, 如果查询中包含这样的数据, 在排序等操作时, 就不能使用内存临时表, 必须使用磁盘临时表进行, 而且对于这种数据, MySQL 还需要二次查询, 会使 SQL 性能变的很差, 如果一定要使用, 建议将 TEXT, BLOB 放到单独的扩展表, 查询时必要使用 select * , 而是查询指定列, 不需要 TEXT 时不要查询 TEXT 或 BLOB 类型只能使用前缀索引 :因为MySQL对索引字段长度是有限制的，所以TEXT类型只能使用前缀索引，并且TEXT列上是不能有默认值的 3. 避免使用 ENUM 类型修改 ENUM 类型需要使用 ALTER 语句, 并且 ENUM 类型的 ORDER BY 操作效率低, 需要额外操作 4. 尽可能将所有列定义为 NOT NULL索引 NULL 列需要额外的空间来保存, 所以要占用更多的空间, 进行比较和计算时都要对 NULL 值进行特别处理 5. 使用 Timestamp 或 DateTime 存储时间MySQL - 关于时间问题的一些思考 6. 同财务相关的金额类数据必须使用 decimal 类型float, double 为非精准浮点, decimal 是精准浮点, decimal 在计算时不会丢失精度, 占用空间由定义宽度决定, 每 4 个字节可以存储 9 位数字(小数点要占用 1 字节), 可存储比 bigint 更大的整型数据 索引设计规范1. 限制每张表的索引数量, 建议的单张表不超过 5 个索引并不是越多越好, 我们知道索引可以增加查询效率, 但是如果使用存在问题索引会降低写入的效率, 有些情况也会降低查询效率 MySQL 优化器在选择如何优化查询时, 会根据统一信息, 对每一个可以用到的索引进行评估,生成一个最好的执行计划, 如果同时有很多个索引都可以用于查询, 就会增加 MySQL 优化器生成执行计划的时间, 降低查询性能 2. 禁止给表中的每一列都建立单独的索引5.6 版本之前，一个 SQL 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好 3. Innodb 表必须存在主键Innodb是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的每个表都可以有多个索引，但是表的存储顺序只能有一种Innodb是按照主键索引的顺序来组织表的 不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引）不要使用 UUID,MD5,HASH, 字符串列作为主键（无法保证数据的顺序增长）主键建议使用自增ID值 索引列建议 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段 多表 JOIN 的关联列 条件合适的情况下建立联合索引, 避免每个单独列都建立索引 索引顺序问题索引建立的目的是 : 通过索引进行数据查找, 减少随机 IO, 增加查询性能, 索引能过滤出越少的数据则从磁盘中读取的数据也就越少 区分度最高的放在联合索引的最左侧（区分度&#x3D;列中不同值的数量&#x2F;列的总行数） 尽量将字段长度小的列放在联合索引的最左侧（字段长度越小，一页能存储的数据量越大，IO性能也就越好） 使用最频繁的列放到联合索引最左侧（较少的建立一些索引） 避免建立冗余索引和重复索引原因 : 增加查询优化器生成执行计划的时间 重复索引示例：primary key(id)、index(id)、unique index(id)冗余索引示例：index(a,b,c)、index(a,b)、index(a) 对于频繁的查询优先考虑使用覆盖索引原因 : 避免 Innodb 表进行索引的二次查询 可以将随机 IO 变为顺序 IO 加快查询速度 详情 : MySQL - 索引机制 数据库 SQL 开发规范1. 建议使用预编译语句进行数据库操作预编译语句可以重复使用这些计划，减少 SQL 编译所需要的时间，还可以解决动态 SQL 所带来的 SQL 注入的问题, 只传参数，比传递 SQL 语句更高效, 相同语句可以一次解析，多次使用，提高处理效率 2. 避免数据类型隐式转换隐式转换会导致索引失效, 在单次查询数据很多的情况下, 若查询列隐式转换将会降低效率 3. 充份利用已建立的索引example : 避免使用双 % 的查询条件 如 name like %loger% , 若无前置 % 只有后置 % , 是可以用到列上的索引的 一个 SQL 只能利用到复合索引中的一列进行查询 如有 a, b, c 列的联合索引，在查询条件中有 a 列的范围查询，则在 b, c 列上的索引将不会被用到，在定义联合索引时，如果 a 列要用到范围查找的话，就要把 a 列放到联合索引的右侧 使用 LEFT JOIN 或 NOT EXISTS 来优化 NOT IN 操作 NOT INT 会导致索引失效 4. 数据库设计时, 需考虑后续扩展情况5. 程序连接不同数据库使用不同账号, 进行跨库查询为数据库迁移和分库分表留出余地, 降低业务耦合度, 避免权限过大而产生的安全风险 6. 禁止使用 SELECT *消耗更多的 CPU 和 IO 以网络带宽资源, 无法使用覆盖索引, 可以减少表结构变更带来的影响 7. 禁止使用不含字段列表的 INSERT 语句如： insert into values (‘a’,’b’,’c’);应使用 insert into t(c1,c2,c3) values (‘a’,’b’,’c’); 8. 避免使用子查询, 可以将子查询优化为 JOIN 操作通常子查询在 IN 子句中, 且子查询为简单 SQL (不包含 union、group by、order by、limit 从句) 时, 才可以将子查询转化为关联查询进行优化 子查询性能差的原因 :子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响, 特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大, 由于子查询会产生大量的临时表也没有索引，所以会消耗过多的CPU和IO资源，产生大量的慢查询 9. 避免使用 JOIN 关联太多表对于Mysql来说，是存在关联缓存的，缓存的大小可以由join_buffer_size参数进行设置在Mysql中，对于同一个SQL多关联（join）一个表，就会多分配一个关联缓存，如果在一个SQL中关联的表越多，所占用的内存也就越大 如果程序中大量的使用了多表关联的操作，同时join_buffer_size设置的也不合理的情况下，就容易造成服务器内存溢出的情况，就会影响到服务器数据库性能的稳定性 同时对于关联操作来说，会产生临时表操作，影响查询效率Mysql最多允许关联61个表，建议不超过5个 10. 减少同数据库交互次数数据库更适合处理批量操作, 合并多个相同的操作在一起, 可以提高处理效率 11. 对应同一列进行 OR 判断时, 使用 IN 替代 ORIN 的值不要超过 500 个IN 操作可以更有效的利用索引，OR 大多数情况下很少能利用到索引 12. 禁止使用 ORDER BY RAND() 进行随机排序会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的CPU和IO及内存资源 推荐在程序中获取一个随机值，然后从数据库中获取数据的方式 13. WHERE 从句中禁止对列进行函数转换和计算会导致索引失效 14. 在明显不会有重复值时使用 UNION ALL 而不是 UNIONUNION 会把两个结果集的所有数据放到临时表中后再进行去重操作UNION ALL 不会再对结果集进行去重操作 15. 拆分复杂的大 SQL 为多个小 SQL大SQL:逻辑上比较复杂，需要占用大量 CPU 进行计算的 SQL, MySQL 一个 SQL 只能使用一个 CPU 进行计算, SQL 拆分后可以通过并行执行来提高处理效率 数据库操作行为规范超 100 万的批量写操作, 要分批次进行操作 大批量操作可能会造成严重的主从延迟 主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间，而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况 binlog 日志为 row 格式时会产生大量日志 大批量写操作会产生大量日志，特别是对于row格式二进制数据而言，由于在row格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因 避免产生大事务操作 大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对MySQL的性能产生非常大的影响, 特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批 对于大表使用 pt-online-schema-change 修改表结构 避免大表修改产生的主从延迟 避免在对表字段进行修改时进行锁表 对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的 pt-online-schema-change它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器, 把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉, 把原来一个 DDL 操作，分解成多个小的批次进行","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"}]},{"title":"Java 泛型详解","slug":"Java-泛型详解","date":"2022-11-08T08:23:12.000Z","updated":"2022-11-09T06:06:34.290Z","comments":true,"path":"2022/11/08/Java-泛型详解/","link":"","permalink":"http://logerjava.github.io/2022/11/08/Java-%E6%B3%9B%E5%9E%8B%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"概述泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用&#x2F;调用时传入具体的类型（类型实参）。 泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。 举例12345678List list = new ArrayList();list.add(&quot;loger&quot;);list.add(100);for(int i = 0; i&lt; list.size();i++)&#123; String str = (String)list.get(i); log.info(&quot;泛型测试&quot;,&quot;str = &quot; + str);&#125; 运行结果 1java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String ArrayList 中可以存放任意类型, 当上述情况, 其中即存在 Integer 又存在 String, 且都以 String 的方式使用时, 程序就会报错, 泛型可以解决此类问题 1List&lt;String&gt; list = new ArrayList&lt;String&gt;(); 声明带泛型的集合, 在集合内类型不匹配时, 会直接报错 特性泛型只在编辑阶段有效 123456789List&lt;String&gt; stringArrayList = new ArrayList&lt;String&gt;();List&lt;Integer&gt; integerArrayList = new ArrayList&lt;Integer&gt;();Class classStringArrayList = stringArrayList.getClass();Class classIntegerArrayList = integerArrayList.getClass();if(classStringArrayList.equals(classIntegerArrayList))&#123; log.info(&quot;类型相同&quot;);&#125; 输出结果：类型相同 通过上面的例子可以证明，在编译之后程序会采取去泛型化的措施。也就是说 Java 中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段。 对此总结成一句话：泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。 泛型的使用泛型类1234567891011121314// 此处 T 可以使用任意表示, T、E、K、V 均可// 实例化时必须指定 T 的具体类型public class Test&lt;T&gt; &#123; // T 的类型为外部指定 private T key; public Test(T key) &#123; this.key = key; &#125; public T getKey() &#123; return key; &#125;&#125; 传入实参的类型与泛型相同, 如不做泛型限制, 则会根据传入实参做相应限制 123456// 泛型限制Test&lt;String&gt; stringTest = new Test&lt;&gt;(&quot;loger&quot;);Test&lt;Integer&gt; integerTest = new Test&lt;&gt;(333);// 非限制Test test = new Test&lt;&gt;(33.33); 泛型接口1234// 定义一个泛型接口public interface Test&lt;T&gt; &#123; public T next(); &#125; 当实现泛型接口未传入实参时 1234567891011/** * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中 * 即：class TestImpl&lt;T&gt; implements Test&lt;T&gt;&#123; * 如果不声明泛型，如：class TestImpl implements Test&lt;T&gt;，编译器会报错：&quot;Unknown class&quot; */class TestImpl&lt;T&gt; implements Test&lt;T&gt;&#123; @Override public T next() &#123; return null; &#125; &#125; 当实现泛型接口的类，传入泛型实参时 1234567891011121314151617/** * 传入泛型实参时： * 定义一个生产器实现这个接口,虽然我们只创建了一个泛型接口 Test&lt;T&gt; * 但是我们可以为 T 传入无数个实参，形成无数种类型的 Test 接口 * 在实现类实现泛型接口时，如已将泛型类型传入实参类型，则所有使用泛型的地方都要替换成传入的实参类型 * 即：TestImpl&lt;T&gt;，public T next();中的的T都要替换成传入的 String 类型 */public class TestImpl implements Test&lt;String&gt; &#123; private String[] fruits = new String[]&#123;&quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot;&#125;; @Override public String next() &#123; Random rand = new Random(); return fruits[rand.nextInt(3)]; &#125;&#125; 泛型通配符试想一个问题 Integer 是 Number 的一个子类, 而 Test&lt;Integer&gt; 和 Test&lt;Number&gt; 实际上是相同的基本类型, 那么 Test&lt;Number&gt; 作为形参的方法中, 能否使用 Test&lt;Ingeter&gt; 实例传入呢 ? 123public void showValue(Test&lt;Number&gt; arg) &#123; log.info(arg.getKey()); &#125; 1234Test&lt;Integer&gt; integerTest = new Test&lt;&gt;(123);Test&lt;Number&gt; numberTest = new Test&lt;&gt;(456);showValue(integerTest); 很明显编译的时候就报错了 Test&lt;java.lang.Integer&gt; cannot be applied to Test&lt;java.lang.Number&gt; 由此可以看出: 同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的 在处理上述问题时, 可以将泛型替换为 ? 123public void showValue(Test&lt;?&gt; arg) &#123; log.info(arg.getKey()); &#125; 注意, 此处 ? 代表的是类型实参, 而非形参, 换一种说话就是可以把 ? 看成所有类的父类, 它可以解决当具体类型不确定时, ? 即是通配符 泛型方法12345678910111213/** * 泛型方法的基本介绍 * @param clazz 传入的泛型实参 * @return T 返回值为T类型 * 说明： * 1）public 与 返回值中间 &lt;T&gt; 非常重要, 可以理解为声明此方法为泛型方法 * 2）只有声明了 &lt;T&gt; 的方法才是泛型方法, 泛型类中的使用了泛型的成员方法并不是泛型方法 * 3）&lt;T&gt; 表明该方法将使用泛型类型 T , 此时才可以在方法中使用泛型类型 T * 4）与泛型类的定义一样, 此处 T 可以随便写为任意标识, 常见的如 T、E、K、V 等形式的参数常用于表示泛型 */public &lt;T&gt; T test(Class&lt;T&gt; clazz) throws Exception&#123; return clazz.newInstance();&#125; 泛型上下边界在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类 123public void showVale(Test&lt;? extends Number&gt; test)&#123; log.info(obj.getKey());&#125; 这样就规定了泛型的上边界, 传入的类型实参必须是指定类型的子类型 1234Test&lt;String&gt; test1 = new Test&lt;String&gt;(&quot;11111&quot;);Test&lt;Integer&gt; test2 = new Test&lt;Integer&gt;(2222);Test&lt;Float&gt; test3 = new Test&lt;Float&gt;(2.4f);Test&lt;Double&gt; test4 = new Test&lt;Double&gt;(2.56); 在编译时, test1 会报错, 因为 String 并不是 Number 的子类型","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://logerjava.github.io/tags/Java/"}]},{"title":"MySQL 主从复制","slug":"MySQL主从复制","date":"2022-11-08T05:32:44.000Z","updated":"2022-11-09T06:02:32.476Z","comments":true,"path":"2022/11/08/MySQL主从复制/","link":"","permalink":"http://logerjava.github.io/2022/11/08/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","excerpt":"","text":"主从复制原理 当 Master 节点进行 insert、update、delete 操作时，会按顺序写入到 binlog 中 salve 从库连接 master 主库，Master 有多少个 slave 就会创建多少个 binlog dump 线程 当 Master 节点的 binlog 发生变化时，binlog dump 线程会通知所有的 salve 节点，并将相应的 binlog 内容推送给 slave 节点 I&#x2F;O 线程接收到 binlog 内容后，将内容写入到本地的 relay-log SQL 线程读取 I&#x2F;O 线程写入的 relay-log，并且根据 relay-log 的内容对从数据库做对应的操作 这里有很重要的两个问题 : 从库同步主库数据的过程是串行化的, 也就是说主库上并行的操作, 在从库上会串行化执行, 由于从库从主库拷贝日志以及串行执行 SQL 的特点, 在高并发场景下, 从库的数据势必会比主库慢, 存在延迟, 所以经常出现刚写入主库的数据读不到的情况 如果主库突然宕机, 此时数据还没有同步到从库, 那么有些数据从库上是没有的, 会出现数据丢失情况 MySQL 存在两个机制解决上面的问题 : 半同步复制 : 主要解决主库数据丢失问题, 也叫做 semi-sync 复制, 指主库写入 binlog 日志之后, 就会强制将此时的数据立即同步到从库, 从库将日志写入自己本地的 relay log 之后, 返回一个 ack 给主库, 主库接收到至少一个从库的 ack 才会认为写操作完成了 并行复制 : 主要解决同步延时问题, 指从库开启多线程, 并行读取 relay log 中不同库的日志, 然后并行重放不同库的日志, 这是库级别的并行 如何实现主从复制这里举例是一主一从 Master登录 MySQL 1mysql -u root -p 创建用户 1234# 10.1.30.113 是 slave 从机的 IPGRANT REPLICATION SLAVE ON *.* to &#x27;root&#x27;@&#x27;10.1.30.113&#x27; identified by &#x27;1qaz@WSX&#x27;;# 刷新系统权限表的配置FLUSH PRIVILEGES; 在 etc&#x2F;my.cnf 增加以下配置 12345678# 开启binloglog-bin=mysql-binserver-id=114# 需要同步的数据库，如果不配置则同步全部数据库binlog-do-db=test_db# binlog日志保留的天数，清除超过10天的日志# 防止日志文件过大，导致磁盘空间不足expire-logs-days=10 重启 MySQL 1service mysql restart 通过下方命令查看当前 binlog 日志信息 1show master status\\G; Slave在 etc&#x2F;my.cnf 增加以下配置 12# 不要和其他mysql服务id重复即可server-id=114 登录 MySQL 1mysql -u root -p 输入以下命令 : MASTER_HOST : 主机 IP MASTER_USER: 之前创建的用户账号 MASTER_PASSWORD : 之前创建的用户密码 MASTER_LOG_FILE : master 主机的 binlog 日志名称 MASTER_LOG_POS : binlog 日志偏移量 master_port : 端口 1CHANGE MASTER TO MASTER_HOST=&#x27;10.1.30.114&#x27;,MASTER_USER=&#x27;root&#x27;,MASTER_PASSWORD=&#x27;1qaz@WSX&#x27;,MASTER_LOG_FILE=&#x27;mysql-bin.000007&#x27;,MASTER_LOG_POS=862,master_port=3306; 重新启动 1start slave; 启动下方命令校验 1show slave status\\G; 判断同步成功方式 : 首先 Master_Log_File 和 Relay_Master_Log_File 所指向的文件必须一致 其次 Relay_Log_Pos 和 Exec_Master_Log_Pos 的为止也要一致才行 测试12345678910CREATE TABLE `tb_role` ( `role_id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;角色id&#x27;, `role_name` varchar(30) DEFAULT NULL COMMENT &#x27;角色名称&#x27;, `state` tinyint(1) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;1启用0停用,默认0&#x27;, `create_by` varchar(40) DEFAULT NULL COMMENT &#x27;创建人&#x27;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;, `remark` varchar(100) DEFAULT NULL COMMENT &#x27;备注&#x27;, PRIMARY KEY (`role_id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8; 在 master 执行上述 SQL 同步到 slave , 表示配置成功 常见问题配置失败出现的问题常见于 Slave_IO_Running: No 或 Slave_SQL_Running: No , 通常是配置读取文件出现问题或事务回滚造成的主从问题, 由于问题很多不做赘述, 列举几个类似问题的博客 : https://blog.csdn.net/zzddada/article/details/113352717 https://blog.csdn.net/weixin_30657999/article/details/99613614 https://blog.csdn.net/lihuarongaini/article/details/101299375","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"}]},{"title":"为什么要使用消息队列, 优缺点, 各消息队列对比","slug":"whyMQ","date":"2022-11-07T07:53:14.000Z","updated":"2022-11-09T06:02:44.487Z","comments":true,"path":"2022/11/07/whyMQ/","link":"","permalink":"http://logerjava.github.io/2022/11/07/whyMQ/","excerpt":"","text":"为什么使用消息队列解耦 如上方场景, A 系统通过接口调用方式发送数据到 B, C, D 系统, 此时新增 E 系统也需要此数据该如何解决 ? 此时又新增了其他系统呢 ? B 系统在某个时间节点不需要 A 系统的数据了该如何解决 ? 在上方场景中 A 系统不仅和 B, C, D 等系统严重耦合在一起, 并且要时刻考虑其他系统的状态, 如果宕机是否要重新发送, 是否需要存储消息等, 负责人的讲 A 系统负责人会很痛苦 如果改用 MQ 方式处理, A 系统产生数据, 直接发送到 MQ 中, 其余需要数据的系统到 MQ 中消费, B 系统不需要则取消消费, 这种情况下 A 系统就摆脱了束缚, 无需考虑调用是否成功, 是否超时等问题, 如下图 异步 如上场景, 假设 A 系统接收到用户请求需要本地持久化数据, 过程为 3ms, 后 B, C, D 写库总计 3 + 300 + 450 + 200 &#x3D; 953ms, 总体接近 1s, 在一般的项目中我们要求基本上是请求响应基本上是对用户无感知的, 大概 200ms 以内完成, 以上情况很难接受 此时添加 MQ, A 系统发送三条消息到 MQ 中耗时 5ms, 总计 3 + 5 &#x3D; 8ms, 直接返回后续操作在后台完成 削峰考虑如下场景, 从早晨 0:00 开始到下午 13:00, 系统 A 每秒并发请求基本维持在 30 左右, 在 13:00 到 14:00 每秒请求激增到 5k+, 系统基于 MySQL 直连, 这时会有每秒 5k+ 的请求打入数据库 一般的 MySQL 很明显无法抗住这种请求级别, 2k 左右大概是极限, 很可能直接宕机, 用户也就无法继续操作系统, 但是经过高峰期后又再度恢复为每秒 30 的请求量 这个时候我们考虑接入 MQ 处理, 每秒 5k+ 的请求写入 MQ, 系统 A 每秒至多处理 2k 的请求, 那么就仅拉取 2k 的请求, 只要不超过处理极限就可以, 这样在最高峰值期间服务并不会挂掉, 每秒 5k 左右的请求进入 MQ, 2k 左右的请求被消费, 这样可能会导致几十万甚至百万的请求积压在 MQ 中, 但是短暂的积压是没有关系的, 经历过高峰期后只有每秒 30 的请求量, 但是系统还是在按照每秒 2k 左右的速度消费, 高峰期过后用不了多久就可以处理结束 消息队列的优缺点优点 : 解耦, 异步, 削峰 缺点 : 可用性降低 : 系统引入的外部依赖越多则可用性越低, 根据上面的场景, 本身是 A, B, C, D 四个系统的问题, 接入 MQ 后需要考虑 MQ 的维护问题, 如果 MQ 宕机则整套系统都将崩溃 复杂度提高 : 新增 MQ 后需要考虑消息幂等问题(是否重复), 消息丢失问题, 顺序等 一致性问题 : 在将消息发送到 MQ 后返回成功, 但是不一定真的全部成功, 有可能 B, C 写入成功而 D 却失败等问题, 会导致数据不一致 综上所属消息队列实际上并没有想象的那么简单, 引入消息队列确实可以带来好处, 但是也会衍生出另一些问题, 针对某些必要使用 MQ 的场景我们需要提前准备问题的解决方案, 难度系统直线上升, 但是关键时刻消息队列是起决定性作用的技术, 该用还是要用 ActiveMQ、RabbitMQ、RocketMQ、Kafka 对比 ActiveMQ RabbitMQ RocketMQ Kafka 单机吞吐量 万级，比 RocketMQ、Kafka 低一个数量级 同 ActiveMQ 10 万级，支撑高吞吐 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 topic 数量对吞吐量的影响 topic 可以达到几百&#x2F;几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 时效性 ms 级 微秒级，这是 RabbitMQ 的一大特点，延迟最低 ms 级 延迟在 ms 级以内 可用性 高，基于主从架构实现高可用 同 ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到 0 丢失 同 RocketMQ 功能支持 MQ 领域的功能极其完备 基于 erlang 开发，并发能力很强，性能极好，延时很低 MQ 功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 以前很多人用 ActiveMQ , 但是现在用的很少, 并且社区不活跃, 不建议使用 RabbitMQ 社区很活跃, 但是 erlang 语言导致 RabbitMQ 处于基本不可控的状态, 也无法做到自定义 RocketMQ 来自阿里, 质量有保证, 毕竟有双 11 检验, 但是目前 RocketMQ 已经捐献给 Apache, 并且活跃度不是很高, 不过毕竟是 Java 写的可控性还是有的, 如果对公司技术自信的可以考虑 Kafka 一般适用于大数据领域, 日志采集, 实时计算","categories":[],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://logerjava.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]}],"categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://logerjava.github.io/tags/Tools/"},{"name":"Java","slug":"Java","permalink":"http://logerjava.github.io/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"http://logerjava.github.io/tags/Linux/"},{"name":"Nacos","slug":"Nacos","permalink":"http://logerjava.github.io/tags/Nacos/"},{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"},{"name":"消息队列","slug":"消息队列","permalink":"http://logerjava.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]}