{"meta":{"title":"logerJava","subtitle":"","description":"","author":"loger","url":"http://logerJava.github.io","root":"/"},"pages":[{"title":"categories","date":"2018-09-30T09:25:30.000Z","updated":"2022-11-04T08:29:46.112Z","comments":true,"path":"categories/index.html","permalink":"http://logerjava.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-09-30T10:23:38.000Z","updated":"2022-11-04T08:31:26.145Z","comments":true,"path":"tags/index.html","permalink":"http://logerjava.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MySQL 主从复制","slug":"MySQL主从复制","date":"2022-11-08T05:32:44.000Z","updated":"2022-11-08T05:46:29.808Z","comments":false,"path":"2022/11/08/MySQL主从复制/","link":"","permalink":"http://logerjava.github.io/2022/11/08/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","excerpt":"","text":"主从复制原理 当 Master 节点进行 insert、update、delete 操作时，会按顺序写入到 binlog 中 salve 从库连接 master 主库，Master 有多少个 slave 就会创建多少个 binlog dump 线程 当 Master 节点的 binlog 发生变化时，binlog dump 线程会通知所有的 salve 节点，并将相应的 binlog 内容推送给 slave 节点 I&#x2F;O 线程接收到 binlog 内容后，将内容写入到本地的 relay-log SQL 线程读取 I&#x2F;O 线程写入的 relay-log，并且根据 relay-log 的内容对从数据库做对应的操作 这里有很重要的两个问题 : 从库同步主库数据的过程是串行化的, 也就是说主库上并行的操作, 在从库上会串行化执行, 由于从库从主库拷贝日志以及串行执行 SQL 的特点, 在高并发场景下, 从库的数据势必会比主库慢, 存在延迟, 所以经常出现刚写入主库的数据读不到的情况 如果主库突然宕机, 此时数据还没有同步到从库, 那么有些数据从库上是没有的, 会出现数据丢失情况 MySQL 存在两个机制解决上面的问题 : 半同步复制 : 主要解决主库数据丢失问题, 也叫做 semi-sync 复制, 指主库写入 binlog 日志之后, 就会强制将此时的数据立即同步到从库, 从库将日志写入自己本地的 relay log 之后, 返回一个 ack 给主库, 主库接收到至少一个从库的 ack 才会认为写操作完成了 并行复制 : 主要解决同步延时问题, 指从库开启多线程, 并行读取 relay log 中不同库的日志, 然后并行重放不同库的日志, 这是库级别的并行 如何实现主从复制这里举例是一主一从 Master登录 MySQL 1mysql -u root -p 创建用户 1234# 10.1.30.113 是 slave 从机的 IPGRANT REPLICATION SLAVE ON *.* to &#x27;root&#x27;@&#x27;10.1.30.113&#x27; identified by &#x27;1qaz@WSX&#x27;;# 刷新系统权限表的配置FLUSH PRIVILEGES; 在 etc&#x2F;my.cnf 增加以下配置 12345678# 开启binloglog-bin=mysql-binserver-id=114# 需要同步的数据库，如果不配置则同步全部数据库binlog-do-db=test_db# binlog日志保留的天数，清除超过10天的日志# 防止日志文件过大，导致磁盘空间不足expire-logs-days=10 重启 MySQL 1service mysql restart 通过下方命令查看当前 binlog 日志信息 1show master status\\G; Slave在 etc&#x2F;my.cnf 增加以下配置 12# 不要和其他mysql服务id重复即可server-id=114 登录 MySQL 1mysql -u root -p 输入以下命令 : MASTER_HOST : 主机 IP MASTER_USER: 之前创建的用户账号 MASTER_PASSWORD : 之前创建的用户密码 MASTER_LOG_FILE : master 主机的 binlog 日志名称 MASTER_LOG_POS : binlog 日志偏移量 master_port : 端口 1CHANGE MASTER TO MASTER_HOST=&#x27;10.1.30.114&#x27;,MASTER_USER=&#x27;root&#x27;,MASTER_PASSWORD=&#x27;1qaz@WSX&#x27;,MASTER_LOG_FILE=&#x27;mysql-bin.000007&#x27;,MASTER_LOG_POS=862,master_port=3306; 重新启动 1start slave; 启动下方命令校验 1show slave status\\G; 判断同步成功方式 : 首先 Master_Log_File 和 Relay_Master_Log_File 所指向的文件必须一致 其次 Relay_Log_Pos 和 Exec_Master_Log_Pos 的为止也要一致才行 测试12345678910CREATE TABLE `tb_role` ( `role_id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;角色id&#x27;, `role_name` varchar(30) DEFAULT NULL COMMENT &#x27;角色名称&#x27;, `state` tinyint(1) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;1启用0停用,默认0&#x27;, `create_by` varchar(40) DEFAULT NULL COMMENT &#x27;创建人&#x27;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;, `remark` varchar(100) DEFAULT NULL COMMENT &#x27;备注&#x27;, PRIMARY KEY (`role_id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8; 在 master 执行上述 SQL 同步到 slave , 表示配置成功 常见问题配置失败出现的问题常见于 Slave_IO_Running: No 或 Slave_SQL_Running: No , 通常是配置读取文件出现问题或事务回滚造成的主从问题, 由于问题很多不做赘述, 列举几个类似问题的博客 : https://blog.csdn.net/zzddada/article/details/113352717 https://blog.csdn.net/weixin_30657999/article/details/99613614 https://blog.csdn.net/lihuarongaini/article/details/101299375","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"}]},{"title":"为什么要使用消息队列, 优缺点, 各消息队列对比","slug":"whyMQ","date":"2022-11-07T07:53:14.000Z","updated":"2022-11-08T02:19:55.721Z","comments":false,"path":"2022/11/07/whyMQ/","link":"","permalink":"http://logerjava.github.io/2022/11/07/whyMQ/","excerpt":"","text":"为什么使用消息队列解耦 如上方场景, A 系统通过接口调用方式发送数据到 B, C, D 系统, 此时新增 E 系统也需要此数据该如何解决 ? 此时又新增了其他系统呢 ? B 系统在某个时间节点不需要 A 系统的数据了该如何解决 ? 在上方场景中 A 系统不仅和 B, C, D 等系统严重耦合在一起, 并且要时刻考虑其他系统的状态, 如果宕机是否要重新发送, 是否需要存储消息等, 负责人的讲 A 系统负责人会很痛苦 如果改用 MQ 方式处理, A 系统产生数据, 直接发送到 MQ 中, 其余需要数据的系统到 MQ 中消费, B 系统不需要则取消消费, 这种情况下 A 系统就摆脱了束缚, 无需考虑调用是否成功, 是否超时等问题, 如下图 异步 如上场景, 假设 A 系统接收到用户请求需要本地持久化数据, 过程为 3ms, 后 B, C, D 写库总计 3 + 300 + 450 + 200 &#x3D; 953ms, 总体接近 1s, 在一般的项目中我们要求基本上是请求响应基本上是对用户无感知的, 大概 200ms 以内完成, 以上情况很难接受 此时添加 MQ, A 系统发送三条消息到 MQ 中耗时 5ms, 总计 3 + 5 &#x3D; 8ms, 直接返回后续操作在后台完成 削峰考虑如下场景, 从早晨 0:00 开始到下午 13:00, 系统 A 每秒并发请求基本维持在 30 左右, 在 13:00 到 14:00 每秒请求激增到 5k+, 系统基于 MySQL 直连, 这时会有每秒 5k+ 的请求打入数据库 一般的 MySQL 很明显无法抗住这种请求级别, 2k 左右大概是极限, 很可能直接宕机, 用户也就无法继续操作系统, 但是经过高峰期后又再度恢复为每秒 30 的请求量 这个时候我们考虑接入 MQ 处理, 每秒 5k+ 的请求写入 MQ, 系统 A 每秒至多处理 2k 的请求, 那么就仅拉取 2k 的请求, 只要不超过处理极限就可以, 这样在最高峰值期间服务并不会挂掉, 每秒 5k 左右的请求进入 MQ, 2k 左右的请求被消费, 这样可能会导致几十万甚至百万的请求积压在 MQ 中, 但是短暂的积压是没有关系的, 经历过高峰期后只有每秒 30 的请求量, 但是系统还是在按照每秒 2k 左右的速度消费, 高峰期过后用不了多久就可以处理结束 消息队列的优缺点优点 : 解耦, 异步, 削峰 缺点 : 可用性降低 : 系统引入的外部依赖越多则可用性越低, 根据上面的场景, 本身是 A, B, C, D 四个系统的问题, 接入 MQ 后需要考虑 MQ 的维护问题, 如果 MQ 宕机则整套系统都将崩溃 复杂度提高 : 新增 MQ 后需要考虑消息幂等问题(是否重复), 消息丢失问题, 顺序等 一致性问题 : 在将消息发送到 MQ 后返回成功, 但是不一定真的全部成功, 有可能 B, C 写入成功而 D 却失败等问题, 会导致数据不一致 综上所属消息队列实际上并没有想象的那么简单, 引入消息队列确实可以带来好处, 但是也会衍生出另一些问题, 针对某些必要使用 MQ 的场景我们需要提前准备问题的解决方案, 难度系统直线上升, 但是关键时刻消息队列是起决定性作用的技术, 该用还是要用 ActiveMQ、RabbitMQ、RocketMQ、Kafka 对比 ActiveMQ RabbitMQ RocketMQ Kafka 单机吞吐量 万级，比 RocketMQ、Kafka 低一个数量级 同 ActiveMQ 10 万级，支撑高吞吐 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 topic 数量对吞吐量的影响 topic 可以达到几百&#x2F;几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 时效性 ms 级 微秒级，这是 RabbitMQ 的一大特点，延迟最低 ms 级 延迟在 ms 级以内 可用性 高，基于主从架构实现高可用 同 ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到 0 丢失 同 RocketMQ 功能支持 MQ 领域的功能极其完备 基于 erlang 开发，并发能力很强，性能极好，延时很低 MQ 功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 以前很多人用 ActiveMQ , 但是现在用的很少, 并且社区不活跃, 不建议使用 RabbitMQ 社区很活跃, 但是 erlang 语言导致 RabbitMQ 处于基本不可控的状态, 也无法做到自定义 RocketMQ 来自阿里, 质量有保证, 毕竟有双 11 检验, 但是目前 RocketMQ 已经捐献给 Apache, 并且活跃度不是很高, 不过毕竟是 Java 写的可控性还是有的, 如果对公司技术自信的可以考虑 Kafka 一般适用于大数据领域, 日志采集, 实时计算","categories":[],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://logerjava.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]}],"categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://logerjava.github.io/tags/MySQL/"},{"name":"消息队列","slug":"消息队列","permalink":"http://logerjava.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]}